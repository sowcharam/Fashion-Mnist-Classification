# -*- coding: utf-8 -*-
"""Week5_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t7PgpQ4J7R1gNLFvVqpj8dq0AhKgyrtf
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.utils

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision.datasets import FashionMNIST as fmnist
from torch.utils.data import DataLoader as dl
import torchvision.transforms as transforms
from torchvision.utils import make_grid

import os
from tqdm.notebook import tqdm
import warnings

warnings.filterwarnings('ignore')

transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean = 0,std = 1)])
train_ds = fmnist(train = True,transform = transform,root = os.getcwd(),download=True)
test_ds = fmnist(train = False,transform = transform,root = os.getcwd(),download=True)

train_loader = dl(train_ds,batch_size=16,shuffle =True,num_workers=4)
test_loader = dl(test_ds,batch_size=16,shuffle=False,num_workers=4)

test_iterator = iter(test_loader)
test_batch = next(test_iterator)
for item in test_batch:
  print(item.size())

def plot_img(batch):
  img_grid = make_grid(batch[0],nrow=4)
  img_np = img_grid.numpy()
  img_np = np.transpose(img_np,(1,2,0))

  plt.figure(figsize=(8,8))
  plt.imshow(img_np)
  plt.title(batch[1])
  plt.xticks([])
  plt.yticks([])
  plt.plot()

print("Testing Data Plot")
plot_img(test_batch)

device = torch.device('cuda' if torch.cuda.is_available() else cpu)
print(device)

class FashionClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        input_size = 784
        self.fc1 = nn.Linear(input_size, 650)
        self.fc2 = nn.Linear(650, 420)
        self.fc3 = nn.Linear(420, 360)
        self.fc4 = nn.Linear(360, 230)
        self.fc5 = nn.Linear(230,10)
        self.dropout = nn.Dropout(p=0.2)
        
    def forward(self, x):
        x = x.view(x.shape[0], -1)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.dropout(F.relu(self.fc2(x)))
        x = self.dropout(F.relu(self.fc3(x)))
        x = self.dropout(F.relu(self.fc4(x)))
        x = F.log_softmax(self.fc5(x), dim=1)
        return x

path = "/content/drive/My Drive/ML_Models"

def evaluate_gpu(model,dl):
  with torch.no_grad():
    total,correct = 0,0

    for batch in dl:
      images,labels = batch
      images,labels = images.to(device),labels.to(device)

      out_prob = model(images)
      out_labels = torch.argmax(out_prob,axis = 1)
      total += labels.size(0)
      correct += (labels == out_labels).sum().item()

  return 100* correct/total

def train_gpu(model,loss_func,optimizer,train_loader,test_loader,epochs = 15):
  hist = {'loss': [],
          'train_accuracy':[],
          'test_accuracy':[]}
  best_val_acc = []

  for epoch_num in tqdm(range(1,epochs+1),desc='Training',total=epochs):
    losses=[]
    for batch in train_loader:
      images,labels = batch
      images,labels = images.to(device),labels.to(device)

      optimizer.zero_grad()
      out = model(images)
      loss = loss_func(out,labels)
      losses.append(loss.item())
      loss.backward()
      optimizer.step()
    hist['loss'].append(np.array(losses).mean())
    train_accuracy = evaluate_gpu(model,train_loader)
    test_accuracy = evaluate_gpu(model,test_loader)

    hist['train_accuracy'].append(train_accuracy)
    hist['test_accuracy'].append(test_accuracy)

  fig,ax = plt.subplots(nrows =1,ncols=2,figsize=(14,7))
  ax[0].plot(range(1,epochs+1),hist['loss'],label ='Loss')
  ax[0].grid()
  ax[0].set_xlabel('Epochs')
  ax[0].set_ylabel('Loss Value')
  ax[0].set_title("Epochs Vs Loss")
  print(hist['loss'])

  ax[1].plot(range(1,epochs+1),hist['train_accuracy'],'m-',label='Training Accuracy')
  ax[1].plot(range(1,epochs+1),hist['test_accuracy'],'g-',label='Test Accuracy')
  print(hist['train_accuracy'],hist['test_accuracy'])
  ax[1].grid()
  ax[1].set_xlabel('Epochs')
  ax[1].set_ylabel('Accuracy')
  ax[1].set_title("Epochs Vs Accuracy")
  plt.show()

  val_acc = hist['test_accuracy']
  is_best = val_acc>=best_val_acc
# Save weights if validation accuracy is best
  checkpoint = {'epoch': epoch_num + 1,
                         'model': FashionClassifier(),
                         'state_dict': model.state_dict(),
                         'optimizer' : optimizer.state_dict()}

        # If best_eval, best_save_path
  if is_best:
    torch.save(checkpoint, '/content/drive/My Drive/checkpoint.pth')
    best_val_acc = max(val_acc)
  print(best_val_acc)
  return model

# Migrate model onto gpu
model = FashionClassifier()
model = model.to(device)
loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(),lr=0.01,momentum = 0.5)

model = train_gpu(model,loss_func,optimizer,train_loader,test_loader)

def load_checkpoint(path):
    checkpoint = torch.load(path)
    model = checkpoint['model']
    model.load_state_dict(checkpoint['state_dict'])
    for parameter in model.parameters():
        parameter.requires_grad = False
    
    model.eval()
    return model

model = load_checkpoint('/content/drive/My Drive/checkpoint.pth')
print(model)